{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/laraselinseyahi/Diabetic-Retinopathy-Classification-using-Deep-Learning/blob/main/CS230_MultiClassClassifier_LaraSelinSeyahi.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Multiclass Classification with ResNet-50 for Diabetic Retinopathy"
      ],
      "metadata": {
        "id": "rgYkEukKSHGR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T5jEmKnAODTe"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.applications import InceptionV3\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bQ2QPTZPLRf9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96c9406e-f24a-41dd-bff8-845eb6df414d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ove3McH6M_Wx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94a67766-f8ac-4d2e-908c-3f74c6866f41"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive\n"
          ]
        }
      ],
      "source": [
        "%cd drive/MyDrive/\n",
        "# upload files to Drive"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = 'diabetic_retinopathy'\n",
        "# Class definitions\n",
        "classes = [\"healthy\", \"mild_dr\", \"moderate_dr\", \"proliferate_dr\", \"severe_dr\"]\n",
        "class_to_idx = {cls: idx for idx, cls in enumerate(classes)}\n",
        "\n",
        "# creates the following dict {\"healthy\": 0, \"mild_dr\": 1, \"moderate_dr\": 2, \"proliferate_dr\": 3, \"severe_dr\": 4}"
      ],
      "metadata": {
        "id": "qtVwPqh3kf8C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Collect file paths and labels\n",
        "file_paths = []\n",
        "labels = []\n",
        "\n",
        "# TensorFlow works efficiently with datasets when file paths and labels are paired,\n",
        "# as it can process the data in batches and apply preprocessing.\n",
        "# This ensures that each image is correctly paired with its label, which is crucial for supervised learning.\n",
        "# This part collects all the image file paths and their corresponding labels.\n",
        "for cls in classes:\n",
        "    class_dir = os.path.join(data_dir, cls)\n",
        "    for file in os.listdir(class_dir):\n",
        "        file_paths.append(os.path.join(class_dir, file))\n",
        "        labels.append(class_to_idx[cls])\n",
        "\n",
        "# Split the dataset into train, validation, and test sets (70% train, remaining eval&test)\n",
        "train_paths, temp_paths, train_labels, temp_labels = train_test_split(\n",
        "    file_paths, labels, test_size=0.3, stratify=labels, random_state=42\n",
        ")\n",
        "# 20% eval, 10% test\n",
        "val_paths, test_paths, val_labels, test_labels = train_test_split(\n",
        "    temp_paths, temp_labels, test_size=0.33, stratify=temp_labels, random_state=42\n",
        ")\n",
        "\n",
        "# Sanity check\n",
        "print(f\"Train: {len(train_paths)}, Validation: {len(val_paths)}, Test: {len(test_paths)}\")\n",
        "\n",
        "# Define image size and batch size\n",
        "IMG_SIZE = (224, 224) # ResNet-50 input size\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# Function to preprocess images\n",
        "def preprocess_image(file_path, label):\n",
        "    # Load the image\n",
        "    image = tf.io.read_file(file_path)\n",
        "    image = tf.image.decode_jpeg(image, channels=3)\n",
        "    image = tf.image.resize(image, IMG_SIZE)\n",
        "    # Perform data augmentation for labels not in [0, 2]\n",
        "    if label == 1 or label == 3 or label == 4:\n",
        "        image = tf.image.random_flip_left_right(image)\n",
        "        image = tf.image.random_flip_up_down(image)\n",
        "        image = tf.image.random_brightness(image, max_delta=0.2)\n",
        "        image = tf.image.random_contrast(image, lower=0.8, upper=1.2)\n",
        "        image = tf.image.random_crop(image, size=(int(IMG_SIZE[0] * 0.9), int(IMG_SIZE[1] * 0.9), 3))\n",
        "        image = tf.image.resize(image, IMG_SIZE)  # Resize back to original size after cropping\n",
        "    image = tf.keras.applications.resnet50.preprocess_input(image) #ResNet-50's requirement of [-1, 1]\n",
        "    return image, label\n",
        "\n",
        "# Create a TensorFlow dataset\n",
        "def create_dataset(file_paths, labels, shuffle=True):\n",
        "    # pair file paths and labels\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((file_paths, labels))\n",
        "    # map function applies preprocess_image function to each image\n",
        "    dataset = dataset.map(preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    if shuffle:\n",
        "        dataset = dataset.shuffle(buffer_size=len(file_paths))\n",
        "    dataset = dataset.batch(BATCH_SIZE).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "    return dataset\n",
        "\n",
        "# Create train, validation, and test datasets\n",
        "train_dataset = create_dataset(train_paths, train_labels)\n",
        "val_dataset = create_dataset(val_paths, val_labels, shuffle=False)\n",
        "test_dataset = create_dataset(test_paths, test_labels, shuffle=False)"
      ],
      "metadata": {
        "id": "vrNBQLDF66XY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf178ddf-d3ea-42c6-e22d-f150c01fde37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 1974, Validation: 566, Test: 280\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adding more layer increases the ability of your model, but the pre-trained ResNet-50 already performs well, so increasing complexity might not be beneficial. Model 1 gave the highest training accuracy.\n",
        "\n",
        "Model 1 Test performance: 85.0%"
      ],
      "metadata": {
        "id": "szR-9uVappsP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# RESNET50 Experiments: Model 1\n",
        "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "for layer in base_model.layers:\n",
        "  layer.trainable = False\n",
        "\n",
        "# Add a new top layer for our 5-class classification\n",
        "model = tf.keras.Sequential([\n",
        "    base_model,\n",
        "    tf.keras.layers.GlobalAveragePooling2D(), # pooling to reduce output size\n",
        "    tf.keras.layers.Dense(5, activation='softmax')  # 5 classes\n",
        "])\n",
        "\n",
        "base_learning_rate = 0.001\n",
        "# since this is multiclass classification, loss is categorical cross entropy loss\n",
        "model.compile(optimizer=Adam(learning_rate=base_learning_rate),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    validation_data=val_dataset,\n",
        "    epochs=50,\n",
        "    callbacks=[\n",
        "        tf.keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True),\n",
        "        # Early stopping for stopping training when validation performance stops improving\n",
        "        tf.keras.callbacks.ModelCheckpoint('resnet50_best_model.keras', save_best_only=True)\n",
        "        # saves best performing model during training\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss, test_acc = model.evaluate(test_dataset)\n",
        "print(f\"Test Accuracy: {test_acc:.2f}\")"
      ],
      "metadata": {
        "id": "At6mUocK8PNe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 677
        },
        "outputId": "a83f09d7-d1ec-4f31-b9a5-9ef011c4b899"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ resnet50 (\u001b[38;5;33mFunctional\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m2048\u001b[0m)          │      \u001b[38;5;34m23,587,712\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ global_average_pooling2d             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)             │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)                   │          \u001b[38;5;34m10,245\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ resnet50 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)          │      <span style=\"color: #00af00; text-decoration-color: #00af00\">23,587,712</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ global_average_pooling2d             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)             │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)                   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">10,245</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m23,597,957\u001b[0m (90.02 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,597,957</span> (90.02 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m10,245\u001b[0m (40.02 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,245</span> (40.02 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m23,587,712\u001b[0m (89.98 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,587,712</span> (89.98 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1120s\u001b[0m 5s/step - accuracy: 0.5705 - loss: 1.1119 - val_accuracy: 0.8428 - val_loss: 0.5473\n",
            "Epoch 2/50\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 186ms/step - accuracy: 0.8208 - loss: 0.5011 - val_accuracy: 0.8304 - val_loss: 0.4519\n",
            "Epoch 3/50\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 185ms/step - accuracy: 0.8448 - loss: 0.4146 - val_accuracy: 0.8216 - val_loss: 0.4243\n",
            "Epoch 4/50\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 192ms/step - accuracy: 0.8515 - loss: 0.3908 - val_accuracy: 0.8534 - val_loss: 0.4051\n",
            "Epoch 5/50\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 165ms/step - accuracy: 0.8740 - loss: 0.3314 - val_accuracy: 0.8322 - val_loss: 0.4045\n",
            "Epoch 6/50\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 175ms/step - accuracy: 0.8908 - loss: 0.3049 - val_accuracy: 0.8269 - val_loss: 0.3863\n",
            "Epoch 7/50\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 186ms/step - accuracy: 0.8993 - loss: 0.2900 - val_accuracy: 0.8781 - val_loss: 0.3336\n",
            "Epoch 8/50\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 163ms/step - accuracy: 0.8936 - loss: 0.2751 - val_accuracy: 0.8498 - val_loss: 0.3652\n",
            "Epoch 9/50\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 158ms/step - accuracy: 0.8934 - loss: 0.2811 - val_accuracy: 0.8640 - val_loss: 0.3540\n",
            "Epoch 10/50\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 171ms/step - accuracy: 0.8922 - loss: 0.2644 - val_accuracy: 0.8622 - val_loss: 0.3593\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 13s/step - accuracy: 0.8593 - loss: 0.3588\n",
            "Test Accuracy: 0.85\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# RESNET50 Experiments: Model 2\n",
        "\n",
        "base_model = ResNet50(\n",
        "    weights='imagenet',\n",
        "    include_top=False,\n",
        "    input_shape=(224, 224, 3)\n",
        ")\n",
        "\n",
        "for layer in base_model.layers[-10:]: # unfreezing last 10 layers\n",
        "  layer.trainable = True\n",
        "\n",
        "# Add a new top layer for our 5-class classification\n",
        "model = tf.keras.Sequential([\n",
        "    base_model,\n",
        "    tf.keras.layers.GlobalAveragePooling2D(), # pooling to reduce output size\n",
        "    tf.keras.layers.Dense(5, activation='softmax')  # 5 classes\n",
        "])\n",
        "\n",
        "base_learning_rate = 0.001\n",
        "model.compile(optimizer=Adam(learning_rate=base_learning_rate),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Print model summary\n",
        "model.summary()\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    validation_data=val_dataset,\n",
        "    epochs=10,  # Adjust based on your needs\n",
        "    callbacks=[\n",
        "        tf.keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True),\n",
        "        tf.keras.callbacks.ModelCheckpoint('resnet50_best_model.keras', save_best_only=True)\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss, test_acc = model.evaluate(test_dataset)\n",
        "print(f\"Test Accuracy: {test_acc:.2f}\")"
      ],
      "metadata": {
        "id": "_bxwNHLYDflq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_OQbPO9t3uDF"
      },
      "outputs": [],
      "source": [
        "# RESNET50 Experiments: Model 3\n",
        "\n",
        "base_model = ResNet50(\n",
        "    weights='imagenet',\n",
        "    include_top=False,\n",
        "    input_shape=(224, 224, 3)\n",
        ")\n",
        "\n",
        "for layer in resnet_model.layers:\n",
        "  layer.trainable = False\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    base_model,\n",
        "    tf.keras.layers.GlobalAveragePooling2D(),\n",
        "    tf.keras.layers.Dense(256, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5), # regularization\n",
        "    tf.keras.layers.Dense(5, activation='softmax')  # 5 classes\n",
        "])\n",
        "\n",
        "base_learning_rate = 0.001\n",
        "model.compile(optimizer=Adam(learning_rate=base_learning_rate),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    validation_data=val_dataset,\n",
        "    epochs=10,\n",
        "    callbacks=[\n",
        "        tf.keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True),\n",
        "        tf.keras.callbacks.ModelCheckpoint('resnet50_best_model.keras', save_best_only=True)\n",
        "    ]\n",
        ")\n",
        "\n",
        "test_loss, test_acc = model.evaluate(test_dataset)\n",
        "print(f\"Test Accuracy: {test_acc:.2f}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}